---
created:
  - "{{date: DD-MM-YYYY}} {{time}}"
aliases:
  - "Course Code:"
  - Betriebssysteme
tags:
  - Course/
---
## **ğŸ“Œ EinfÃ¼hrung: Prozesse und Scheduling

Im Rahmen dieser Lehrveranstaltung wurden wir wÃ¶chentlich zu dem Buch [ğŸ”— O-STEP Book](https://pages.cs.wisc.edu/~remzi/OSTEP)
einzeln abgefragt. Wir haben Kapitel 3-38 behandelt. In der Abfrage konnte alles mÃ¶gliche was in den jeweiligen Kapiteln zu finden ist, drankommen. WÃ¶chentlich wurden in etwa 2-3 Kapitel behandelt. 
Diese Seite und die zugehÃ¶rigen Zusammenfassungen wurden **nachtrÃ¤glich** erstellt - also erst im Anschluss an den jeweiligen Kurs. Die Inhalte dienen vor allem dazu, einen **Einblick in die behandelten Themen** zu geben.  
Es kann daher vorkommen, dass einzelne Aspekte **verkÃ¼rzt**, **vereinfacht** oder **nicht vollstÃ¤ndig dokumentiert** sind.

ğŸ”¹ **Kapitel 4 - Prozesse**

- Ein **Prozess** ist ein laufendes Programm mit einem eigenen Adressraum.
- Prozesse haben **ZustÃ¤nde**: **running, ready, waiting**.

ğŸ”¹ **Kapitel 5 - Process API**

- Prozesse werden mit **`fork()`** erstellt und mit **`exec()`** ersetzt.
- `wait()` sorgt dafÃ¼r, dass ein Elternprozess auf sein Kind wartet.

ğŸ”¹ **Kapitel 6 - Direct Execution**

- Ein Programm lÃ¤uft direkt auf der CPU, aber das Betriebssystem verwaltet den Zugriff auf Ressourcen Ã¼ber **System Calls**.

ğŸ”¹ **Kapitel 7 - CPU Scheduling**

- **First-Come, First-Served (FCFS)** â†’ einfacher, aber unfair.
- **Round Robin (RR)** â†’ jeder Prozess erhÃ¤lt eine feste Zeitscheibe.
- **Shortest Job First (SJF)** â†’ optimale Wartezeiten, aber schwer vorherzusagen.

ğŸ”¹ **Kapitel 8 - Multi-Level Feedback Queue (MLFQ)**

- Dynamisches Scheduling, das Prozesse priorisiert, die schnell reagieren mÃ¼ssen.

ğŸ”¹ **Kapitel 9 - Lottery Scheduling**

- Threads erhalten **"Lottoscheine"**, und einer wird zufÃ¤llig zur AusfÃ¼hrung ausgewÃ¤hlt.

ğŸ”¹ **Kapitel 10 - Multi-CPU Scheduling**

- Symmetrisches und asymmetrisches Multi-Prozessor-Scheduling.

ğŸ”¹ **Kapitel 11 - Zusammenfassung der Scheduling-Strategien**

- Vergleich aller Scheduling-Algorithmen und deren Effizienz.

---

## **ğŸ“Œ Teil 2: Speicherverwaltung (Kapitel 12-24)**

ğŸ”¹ **Kapitel 12 - AdressrÃ¤ume**

- Jeder Prozess hat seinen eigenen **virtuellen Adressraum** (Heap, Stack, Code, Data).

ğŸ”¹ **Kapitel 13 - Address Spaces & Code**

- Trennung von **virtuellen und physischen Adressen**.
- OS verwaltet den Speicher mit **Paging oder Segmentierung**.

ğŸ”¹ **Kapitel 14 - Memory API**

- **Heap-Management**: `malloc()`, `free()` und Speicherallokatoren.

ğŸ”¹ **Kapitel 15 - Address Translation**

- **MMU (Memory Management Unit)** Ã¼bersetzt virtuelle in physische Adressen.

ğŸ”¹ **Kapitel 16 - Segmentation**

- Speicher wird in **logische Segmente** unterteilt.
- **Problem**: Fragmentierung.

ğŸ”¹ **Kapitel 17 - Free Space Management**

- **Buddy-System** & **Bitmap-Allokatoren** verwalten freien Speicherplatz.

ğŸ”¹ **Kapitel 18 - EinfÃ¼hrung in Paging**

- **Paging** unterteilt den Speicher in **gleich groÃŸe Seiten**.
- Vorteile: Kein Fragmentierungsproblem wie bei Segmentierung.

ğŸ”¹ **Kapitel 19 - Translation Lookaside Buffer (TLB)**

- **TLB (Translation Lookaside Buffer)** speichert hÃ¤ufig verwendete AdressÃ¼bersetzungen.

ğŸ”¹ **Kapitel 20 - Fortgeschrittene Page Tables**

- **Multi-Level Page Tables** sparen Speicherplatz.
- **Inverted Page Tables** speichern nur verwendete Seiten.

ğŸ”¹ **Kapitel 21 - Swapping: Mechanismen**

- **Swapping** lagert inaktive Prozesse auf die Festplatte aus.

ğŸ”¹ **Kapitel 22 - Swapping: Policies**

- **Wann und wie oft** Prozesse geswappt werden, beeinflusst die Performance.

ğŸ”¹ **Kapitel 23 - VollstÃ¤ndige VM-Systeme**

- Kombiniert **Paging, TLBs und Swapping** fÃ¼r ein effizientes Speichersystem.

ğŸ”¹ **Kapitel 24 - Zusammenfassung der Speicherverwaltung**

- Vergleich von **Paging, Swapping und Segmentierung**.

---

## **ğŸ“Œ Teil 3: Concurrency & Synchronisation (Kapitel 25-34)**

ğŸ”¹ **Kapitel 25 - EinfÃ¼hrung in Concurrency**

- Mehrere Threads kÃ¶nnen parallel laufen, mÃ¼ssen aber synchronisiert werden.

ğŸ”¹ **Kapitel 26 - Thread API**

- **POSIX-Threads (`pthread`)** â†’ `pthread_create()`, `pthread_join()`.

ğŸ”¹ **Kapitel 27 - Locks**

- **Mutexe (`pthread_mutex_lock`)** verhindern Race Conditions.

ğŸ”¹ **Kapitel 28 - Locks mit Spinlocks**

- **Spin Locks** vermeiden teure Kontextwechsel, verbrauchen aber CPU-Zeit.

ğŸ”¹ **Kapitel 29 - Gesperrte Datenstrukturen**

- **Fine-Grained Locking**: Mehrere Locks fÃ¼r verschiedene Teile der Datenstruktur.

ğŸ”¹ **Kapitel 30 - Bedingungsvariablen**

- **`pthread_cond_wait()`** blockiert Threads, bis eine Bedingung erfÃ¼llt ist.

ğŸ”¹ **Kapitel 31 - Semaphoren**

- **`sem_wait()`, `sem_post()`** kontrollieren den Zugriff auf mehrere Ressourcen.

ğŸ”¹ **Kapitel 32 - Race Conditions & Bugs**

- Typische Fehler: **Deadlocks**, **Starvation**, **Lost Updates**.

ğŸ”¹ **Kapitel 33 - Event-basierte Concurrency**

- Alternative zu Threads: **asynchrone Ereignisbehandlung**.

ğŸ”¹ **Kapitel 34 - Zusammenfassung der Synchronisationstechniken**

- Vergleich: **Mutexe, Semaphoren, Bedingungsvariablen, Spinlocks**.


