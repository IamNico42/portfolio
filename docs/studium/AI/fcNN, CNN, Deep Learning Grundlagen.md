

## **Grundlagen des Maschinellen Lernens**

### ğŸ“˜ ErklÃ¤rung:

Beim **Ã¼berwachten Lernen (Supervised Learning)** lernt ein Modell anhand von **Eingabedaten (X)** und den zugehÃ¶rigen **Zielwerten (Y)**, wie es Vorhersagen treffen kann.

In der MNIST-Aufgabe:
- Eingabe: 28x28-Bild von einer Zahl
- Ziel: Welche Ziffer ist darauf zu sehen (z.â€¯B. 5)
    

Wir unterteilen die Daten in:
- **Trainingsdaten** - zum Lernen
- **Validierungsdaten** - zur Kontrolle wÃ¤hrend des Trainings (tun wir "zu viel"?)
- **Testdaten** - zur abschlieÃŸenden Bewertung (wie gut ist das Modell bei neuen, unbekannten Bildern?)
    

**Wichtige Begriffe:**
- **Loss-Funktion**: misst den Fehler â†’ z.â€¯B. `categorical_crossentropy`
- **Optimizer**: passt die Gewichte an â†’ z.â€¯B. `adam`
- **Epochen**: wie oft das Modell alle Trainingsdaten durchlÃ¤uft
- **Batch-GrÃ¶ÃŸe**: Gibt an, **wie viele Trainingsbeispiele gleichzeitig** verarbeitet werden, **bevor** das Modell die Gewichte aktualisiert

## 1. ğŸ“¦ **Was ist das MNIST-Datenset?**

- Datensatz mit **60.000 Trainingsbildern** und **10.000 Testbildern**
- Bilder: **28x28 Pixel**, Graustufen (Werte 0-255)
- Ziel: Ziffern **0 bis 9** automatisch erkennen
- Bilder werden auf **Werte zwischen 0 und 1 normalisiert** (`/255.0`)
- Labels werden in **One-Hot-Encoding** umgewandelt â†’ z.â€¯B. 3 â†’ `[0, 0, 0, 1, 0, ..., 0]`

## 2. ğŸ”¢ **fcNN - Fully Connected Neural Network (Multilayer Perceptron)**

### ğŸ“Œ Aufbau:

- Eingabedaten mÃ¼ssen **geflattet** werden: 28Ã—28 â†’ Vektor mit 784 Werten
- Besteht aus: `Dense`-Layern + Aktivierungsfunktionen (`sigmoid`, `relu`)
- Output-Layer: 10 Neuronen mit `softmax` fÃ¼r Wahrscheinlichkeiten
    

### ğŸ“Œ Eigenschaften:

- **Jede Verbindung** zwischen den Neuronen wird trainiert
- **RÃ¤umliche Struktur** des Bildes geht **verloren**
- Erreicht ca. **97â€¯% Genauigkeit** auf MNIST


## 3. ğŸ§  **CNN - Convolutional Neural Network**

### ğŸ“Œ Aufbau:

- **Arbeitet direkt mit 2D-Bildern** (kein Flatten nÃ¶tig!)
- Typische Layer:
    - `Conv2D`: erkennt lokale Muster mit kleinen Filtern (z.â€¯B. 3x3)
    - `MaxPooling2D`: reduziert GrÃ¶ÃŸe, hebt wichtigste Infos hervor
    - `Flatten`: bereitet Ausgabe fÃ¼r Dense-Schichten vor
    - `Dense + softmax`: Klassifikation
        

### ğŸ“Œ Warum CNNs besser fÃ¼r Bilder sind:

- **Erkennen lokale Muster** wie Kanten, Linien, Kreise
- **Behalten rÃ¤umliche Lage bei**
- **Robust gegenÃ¼ber Verschiebung** von Ziffern im Bild
- Lernen tiefere, abstraktere ReprÃ¤sentationen
- Erreichen **Ã¼ber 99â€¯% Genauigkeit** auf MNIST

## 4. ğŸ§© **Was sind lokale Muster & wie erkennt CNN sie?**

### ğŸ“Œ Lokale Muster:

- Kleine visuelle Merkmale: z.â€¯B. Ecken, Striche, Kreise
- Ein Filter (3Ã—3 oder 5Ã—5) â€scanntâ€œ das Bild
- Multipliziert Filter & Bildausschnitt â†’ ergibt Feature Map
    

### ğŸ“Œ CNN-Schichten lernen:

- FrÃ¼he Layer: Kanten, einfache Muster
- SpÃ¤tere Layer: Formen, Ziffern
- CNN erkennt **was** und **wo** ein Muster ist â†’ fcNN nicht


## 5. âš™ï¸ **Softmax, One-Hot-Encoding und Optimizer**

### âœ… Softmax:

- Wandelt Roh-Ausgaben des Netzes in **Wahrscheinlichkeiten** um
- Beispiel: `[2.3, 5.1, -1.2]` â†’ `[0.1, 0.89, 0.01]`
    
### âœ… One-Hot-Encoding:

- Wandelt Zielklassen in Vektoren mit genau **einer 1** an der richtigen Stelle um
- Wird fÃ¼r die **Loss-Berechnung mit `categorical_crossentropy`** benÃ¶tigt
    
### âœ… Optimizer (`adam`):

- Berechnet, **wie die Gewichte geÃ¤ndert werden mÃ¼ssen**, um den Fehler zu minimieren
- Adam ist **schnell, effizient und selbstanpassend**

## 6. ğŸ“Š **Trainingsmetriken & Auswertung**

- **Accuracy**: Anteil korrekt klassifizierter Bilder
- **Loss**: MaÃŸ fÃ¼r den Vorhersagefehler
- **Confusion Matrix**: Zeigt, welche Klassen wie oft **verwechselt** wurden
- **Trainingsverlauf (Plots)**: visualisiert Lernfortschritt