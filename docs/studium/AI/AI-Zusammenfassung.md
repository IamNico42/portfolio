### ğŸ“˜ **Strukturiertes Lernskript: Teil 1 - Symbolische KI**

(â†’ aus Klausur SS2021)

#### ğŸ§  **1. Suchen & ProblemlÃ¶sen**

**Beispielaufgabe (Wasserkrugproblem)**: Ziel ist ein Zustand mit (x, y, z) = (4, 4, 0)

- **Zustand** = (Inhalt 8l, 5l, 3l)
- **Aktionen** = UmfÃ¼llen zwischen GefÃ¤ÃŸen, nur bis maximal voll oder leer
- **Suchstrategien**:
    
    - **Breitensuche**: prÃ¼ft alle MÃ¶glichkeiten pro Ebene â†’ findet **immer kÃ¼rzeste LÃ¶sung**
    - **Tiefensuche**: geht tief in einen Pfad â†’ **nicht garantiert** kÃ¼rzeste
    - **Iterativ vertiefende Tiefensuche**: wie Tiefensuche, aber in Schritten â†’ **findet auch kÃ¼rzeste**
        

ğŸ‘‰ **Merksatz**: Breitensuche = optimal, aber speicherintensiv

---

#### ğŸ§  **2. Aussagenlogik & Resolution**

## **Was ist der ResolutionskalkÃ¼l?**
> Der **ResolutionskalkÃ¼l** ist ein Verfahren, mit dem man **automatisch prÃ¼fen kann**, ob eine Aussage **logisch aus anderen Aussagen folgt** - also ob ein Argument **gÃ¼ltig** ist.

Beispiel:

- Î±â‚: a âˆ§ b â†’ c
- Î±â‚‚: c â†’ d âˆ¨ e
- Î±â‚ƒ: e â†’ d
- Î³: a â†’ (b â†’ d)
    

â¡ **Ziel**: Mit Resolution zeigen, dass Î³ logisch folgt.

**Schritte:**

1. **Umformen in KNF** (Konjunktive Normalform)
2. **Negation der Zielaussage**
3. **ResolutionskalkÃ¼l anwenden**, bis leere Klausel (Widerspruch) gefunden wird

    

---

#### ğŸ§  **3. Constraint Satisfaction Problems (CSP)**

Beispiel: LÃ¤nder einfÃ¤rben (keine Nachbarn in gleicher Farbe)

- **Strategien beim Backtracking**:
    
    1. **Most Constrained Variable First** - wÃ¤hle Land mit wenigsten mÃ¶glichen Farben
    2. **Most Constraining Variable First** - falls Gleichstand: Land mit meisten Nachbarn zuerst
    3. **Least Constraining Value First** - Farbe, die wenig stÃ¶rt
    4. **Forward Checking** - verbietet ungÃ¼ltige Farben fÃ¼r Nachbarn **nach** Farbwahl
        

â¡ **AC-3 Algorithmus**: prÃ¼ft Paare (z.â€¯B. Land 1 & 2) und schrÃ¤nkt mÃ¶gliche Farben ein, bis **Konsistenz** erreicht

---
### ğŸ¤– **Teil 2 - Maschinelles Lernen & Neuronale Netze**

(â†’ NachprÃ¼fung 2021)

## Was ist **One-Hot-Encoding**?
**One-Hot-Encoding** ist eine Methode, um **Kategorien** (= Klassen) in Zahlen umzuwandeln, sodass sie von **mathematischen Modellen** verstanden werden kÃ¶nnen.

| Klasse | One-Hot-Vektor |
| ------ | -------------- |
| Hund   | `[1, 0, 0]`    |
| Katze  | `[0, 1, 0]`    |
| Maus   | `[0, 0, 1]`    |

### Allgemein:
- **Epoche** = einmal durch alle Trainingsdaten
- **Batch Size** = wie viele Beispiele gleichzeitig gelernt werden
- **Learning Rate** = wie groÃŸ die Schritte beim Gewichts-Update sind
- - **Gewicht (w)**: multipliziert mit Input
- **Bias (b)**: wird **addiert**, um Verschiebung zu ermÃ¶glichen  
    â†’ Funktioniert wie der y-Achsenabschnitt in einer linearen Funktion

### was ist **Gradient Descent**?
- ein **Fehler/Loss** berechnet wird
- dieser **minimiert** werden soll

### Was passiert in einem Trainingsschritt?
FÃ¼r **alle Modelle**, von linear bis CNN:

1. Eingabe durch Netz â†’ **Vorhersage**
2. Vergleich mit Zielwert â†’ **Fehler/Loss**
3. **Gradienten berechnen** = Wie stark Ã¤ndert sich der Fehler, wenn ein Gewicht verÃ¤ndert wird?
4. **Gewichte anpassen mit Gradient Descent**:
    $w = w - \eta \cdot \frac{\partial L}{\partial w}â€‹$
5. Wiederholen (mehr Epochen, mehr Batches)
### was ist **Backpropagation**?
> Backpropagation = â€Fehler rÃ¼ckwÃ¤rts durchs Netz schickenâ€œ, um zu wissen, **welches Gewicht wie viel Schuld hat**

- In **einfachen Modellen** (z.â€¯B. logistische Regression):  
    Backprop ist nur **1 Schritt rÃ¼ckwÃ¤rts**
- In **tiefen Netzen** (z.â€¯B. MLP, CNN):  
    Backpropagation **lÃ¤uft durch alle Layer zurÃ¼ck** und berechnet alle Gradienten

| Modell                 | Loss-Funktion       | Aktivierung   | Optimierungsmethode              |
| ---------------------- | ------------------- | ------------- | -------------------------------- |
| Lineare Regression     | MSE                 | -             | Gradient Descent                 |
| Logistische Regression | Cross Entropy       | Sigmoid       | Gradient Descent + Backprop      |
| MLP / FCNN / CNN       | z.â€¯B. Cross Entropy | ReLU, Softmax | Backprop durch mehrere Schichten |

### ğŸ”¹ **Lineare Regression**

> **Ziel**: Einen **Zahlenwert** vorhersagen (z.â€¯B. Preis, Temperatur)

Formel:
$\hat{y} = a \cdot x + b$

- `x`: Eingabewert (z.â€¯B. GrÃ¶ÃŸe)
- `y`: Ausgabewert (z.â€¯B. Gewicht)
- `a`: Steigung (wie stark y sich mit x verÃ¤ndert)
- `b`: Achsenabschnitt (Startwert)
    

ğŸ“Œ **Beispiel**:  
Du mÃ¶chtest das **Gewicht einer Person** aufgrund ihrer **GrÃ¶ÃŸe** schÃ¤tzen.  
â†’ Je grÃ¶ÃŸer die Person, desto mehr wiegt sie im Schnitt â†’ Lineare Beziehung

---

### ğŸ”¹ **Logistische Regression**

> **Ziel**: Eine **Wahrscheinlichkeit** vorhersagen (z.â€¯B. â€gehÃ¶rt zur Klasse 1â€œ)

Formel:
$$
\sigma(z) = \frac{1}{1 + e^{-z}} \quad \text{wobei } z = a \cdot x + b
$$

- Gibt **Wahrscheinlichkeiten zwischen 0 und 1** aus
- Wird genutzt bei **Klassifikationsaufgaben** (z.â€¯B. "Spam oder nicht?")

ğŸ“Œ **Beispiel**:  
Du mÃ¶chtest vorhersagen, ob eine E-Mail **Spam** ist â†’ 0 = nein, 1 = ja  
Die logistische Regression berechnet: â€Wie sicher bin ich mir, dass es Spam ist?â€œ

Braucht Aktivierungsfunktion weil es dadurch zugÃ¤nglich fÃ¼r Entscheidungen macht statt nur wie bei der linearen Regression einen Wert zu berechnen
## Bekannte Aktivierungsfunktionen:

| Funktion       | Formel                                          | Eigenschaften                                      | Typischer Einsatz                                           | WofÃ¼r                                    |
| -------------- | ----------------------------------------------- | -------------------------------------------------- | ----------------------------------------------------------- | ---------------------------------------- |
| **Sigmoid**    | $\sigma(x) = \frac{1}{1+e^{-x}}$                | glÃ¤ttet auf [0,1], gut fÃ¼r Wahrscheinlichkeiten    | Klassifikation (z.â€¯B. logistische Regression, Output Layer) | Macht Werte zu **Wahrscheinlichkeiten**  |
| **Tanh**       | $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}â€‹$ | Werte zwischen [-1, 1], aber Ã¤hnlich wie Sigmoid   | Hidden Layers (frÃ¼her Standard)                             | **Zentriert**, hilft bei Gradienten      |
| **ReLU**       | $\text{ReLU}(x) = \max(0, x)$                   | lÃ¤sst nur positive Werte durch, **sehr effizient** | Hidden Layers (heute Standard)                              | **Effizient**, verhindert viele Probleme |
| **Leaky ReLU** | $x.wenn.x>0, sonst 0.01x$                       | wie ReLU, aber kleine Negative erlaubt             | Hidden Layers (Alternative zu ReLU)                         | Verhindert, dass Neuronen â€sterbenâ€œ      |
| **Softmax**    | $\frac{e^{x_i}}{\sum e^{x_j}}$â€‹â€‹                | macht Wahrscheinlichkeitsverteilung aus Vektor     | Multiklass-Klassifikation (Output Layer)                    | Gibt **Wahrscheinlichkeitsverteilung**   |

---

#### ğŸ”¥ **3. Cross Entropy Loss**

**Misst den Fehler**, wenn ein neuronales Netz eine Klasse vorhersagen soll.
Formel (bei einer Klasse 1):

$$
\text{Loss} = -\log(\text{p})
$$
- `p` ist die vorhergesagte Wahrscheinlichkeit fÃ¼r die **richtige Klasse**
- Je nÃ¤her `p` an 1 â†’ **kleiner Verlust**
- Je nÃ¤her `p` an 0 â†’ **sehr groÃŸer Verlust**

ğŸ“Œ **Beispiel**:  
Die wahre Klasse ist **Katze**.  
Das Modell sagt mit 90â€¯%: â€Das ist eine Katze.â€œ  
â†’ Guter Wert, niedriger Fehler  
Sagt es nur 10â€¯%: â†’ hoher Fehler, obwohl â€Katzeâ€œ korrekt ist!

| Funktion          | Aufgabe                                 | Beispiel                                              |
| ----------------- | --------------------------------------- | ----------------------------------------------------- |
| **Softmax**       | Macht aus Zahlen Wahrscheinlichkeiten   | `[2.0, 1.0, 0.1] â†’ [0.65, 0.24, 0.11]`                |
| **Cross Entropy** | Vergleicht Vorhersage mit echter Klasse | `loss([0.65, 0.24, 0.11], [0, 1, 0])` = groÃŸer Fehler |

##### âœ… Schritt 1: **Softmax**
> Macht aus den **Roh-Ausgaben** des Netzes (auch â€Logitsâ€œ genannt) **Wahrscheinlichkeiten** fÃ¼r jede Klasse.

ğŸ“Œ Beispiel:

Roh-Ausgabe vom Netz (z.â€¯B. letzte Schicht, noch **keine Wahrscheinlichkeiten**):


`[2.5, 1.0, -0.5]`

Softmax wandelt das um:

`[0.78, 0.18, 0.04]`

â¡ Das Netz â€glaubtâ€œ:

- Klasse 0 mit 78â€¯%
- Klasse 1 mit 18â€¯%
- Klasse 2 mit 4â€¯%
    
##### âœ… Schritt 2: **Cross Entropy**
> Vergleicht diese Wahrscheinlichkeiten mit der **richtigen Klasse** (One-Hot)

ğŸ“Œ Beispiel:  
Die **wahre Klasse** war **Klasse 1** â†’ One-Hot: `[0, 1, 0]`
Cross Entropy Loss schaut dann auf den Wert **bei der 1** (Klasse 1):
$\text{Loss} = -\log(0.18) \approx 1.714$

â†’ Das Netz hat **nicht besonders gut geraten** â†’ also **hoher Fehler**
â†’ je **hÃ¶her die Vorhersage fÃ¼r die richtige Klasse**, desto **niedriger der Verlust**

---

## ğŸŸ£ **3. CNN vs. Fully Connected Layer**

## ğŸ”¥ Was ist **Overfitting**?
> Overfitting bedeutet, dass dein Modell die **Trainingsdaten zu gut auswendig gelernt hat**, aber **auf neuen Daten schlecht funktioniert**.

### ğŸ›  Was hilft gegen Overfitting?
- **Mehr Daten**
- **Dropout** â†’ zufÃ¤lliges Abschalten von Neuronen beim Training
- **Regularisierung** (z.â€¯B. L2)
- **Batch-Normalisierung**
- **FrÃ¼hes Stoppen** (Early Stopping)
- **Datenaugmentation** (z.â€¯B. Bilder leicht kippen, drehen, spiegeln, um mehr Vielfalt zu schaffen)

### ğŸ”¹ **Fully Connected (FC)**

- Jedes Neuron ist mit **allen Neuronen** der nÃ¤chsten Schicht verbunden
- Viele Parameter â†’ hohe Rechenlast
- Keine RÃ¼cksicht auf **rÃ¤umliche Struktur** (z.â€¯B. bei Bildern)

ğŸ“Œ Beispiel: Eingabebild mit 784 Pixeln (28Ã—28) â†’ 100 Neuronen â†’ **78.400 Gewichte!**

---

### ğŸ”¹ **CNN (Convolutional Neural Network)**

- Nutzt **Filter**, die Ã¼ber das Bild â€wandernâ€œ (Faltung)
- Erkennen **Kanten, Texturen, Formen**
- **Weniger Parameter** - z.â€¯B. 10 Filter Ã  3Ã—3 = 90 Gewichte

ğŸ“Œ Vorteil:

- CNNs erkennen **lokale Muster** (z.â€¯B. Augen in Gesichtern)
- Weniger Overfitting
- Besser fÃ¼r Bilder geeignet

Stell dir vor, du hast ein sehr kleines Bild (z.â€¯B. Graustufen, 5Ã—5 Pixel):

### ğŸ“· Bild (Input-Matrix)

```
1  2  3  0  1
4  5  6  1  0
7  8  9  0  1
1  2  3  4  5
0  1  2  3  4

```

Und du hast **einen Filter**, der Kanten in horizontaler Richtung erkennt. Der sieht z.â€¯B. so aus:

### ğŸ§© Filter (3Ã—3 Matrix)

```
-1 -1 -1
 0  0  0
 1  1  1
```

Das ist ein sogenannter **Sobel-Filter**, der **horizontale Kanten** erkennt (oben dunkel, unten hell â†’ z.â€¯B. Augenbraue Ã¼ber Auge).

## ğŸ” Was passiert jetzt?

Der Filter **â€wandertâ€œ Ã¼ber das Bild**, von links nach rechts, oben nach unten, immer 3Ã—3 Ausschnitte.
Bei jedem Schritt wird:

1. Das **Filterelement mit dem Bildausschnitt multipliziert**
2. Die Produkte werden **aufsummiert**
3. Das ergibt **einen Pixel im Ausgabebild**
    

---

### ğŸ” Beispiel-Schritt 1 (linke obere Ecke):

Der 3Ã—3-Ausschnitt aus dem Bild:

```
1  2  3
4  5  6
7  8  9
```

Multipliziert mit dem Filter (elementweise):

`1*-1 + 2*-1 + 3*-1 + 4*0 + 5*0 + 6*0 + 7*1 + 8*1 + 9*1 = -1 -2 -3 + 0 + 0 + 0 + 7 + 8 + 9 = **18**`

â†’ Das ist der **erste Pixel** im Output-Bild

```
18  X  X
X   X  X
X   X  X
```

### ğŸ’¡ Fazit:
> Ein CNN-Filter ist eine kleine Matrix (z.â€¯B. 3Ã—3), die lokal Ã¼ber das Bild lÃ¤uft und **wichtige Muster erkennt**, z.â€¯B. Kanten. Das Netz lernt im Training selbst, **welche Filter am besten funktionieren**.

---

#### ğŸ§  **5. Batch-Normierung**

- **Standardisiert Eingaben pro Mini-Batch**
- Vorteil: schnelleres & stabileres Training
- Formel:
$$
 x' = \frac{x - \text{Mittelwert}}{\text{Standardabweichung} + \varepsilon} \quad\Rightarrow\quad BN(x') = \alpha x' + \beta
$$

---
## ğŸ”´ **L1-Regularisierung**

### ğŸ§® Formel:
$$
\text{Loss} = \text{Fehler} + \lambda \cdot \sum |w|
$$
- Bestraft **alle Gewichte linear**
- Hat den Effekt, dass **viele Gewichte exakt null werden**

## ğŸ”µ **L2-Regularisierung** (das ist die â€Standardâ€œ-Variante)

### ğŸ§® Formel:

$$
\text{Loss} = \text{Fehler} + \lambda \cdot \sum w^2
$$

- `Î»` ist ein Parameter, wie **stark du die Bestrafung** willst
- GroÃŸe Gewichte â†’ **Ã¼berproportional stÃ¤rker bestraft**
- Aber: **Gewichte werden nicht null**, sondern nur **kleiner gehalten**
    

ğŸ“Œ **Was passiert?**  
Das Netz **verteilt die Verantwortung** gleichmÃ¤ÃŸig.  
Es **vermeidet es**, dass ein einzelnes Neuron â€allesâ€œ speichert (und damit Ã¼berfitten kann).

| Name        | Auch genannt | Bestraft groÃŸe â€¦      | Effekt                     | Vorteil                         | Nachteil      |
| ----------- | ------------ | --------------------- | -------------------------- | ------------------------------- | ------------- |
| **L1**      | Lasso        | Absolutwerte          | Macht Gewichte **null**    | Spart Speicher, Feature-Auswahl | Eher instabil |
| **L2**      | Ridge        | Quadrate der Gewichte | Macht Gewichte **kleiner** | Glatteres robusteres Lernen     | Eher trÃ¤ger   |
| Kombination | Elastic Net  | Mischung aus beidem   |                            |                                 |               |



---
#### ğŸ§ª **6. Dropout**

- In jedem Trainingsschritt: zufÃ¤llige Neuronen auf 0(deaktiviert)
- Welche Neuronen deaktiviert werden Ã¤ndert sich in jedem Schritt
- Damit alle Neuronen einmal drankommen und nicht einzelne zu viel trainiert
  werden und zu Superneuronen werden

- Ziel: **Overfitting verhindern**, Netzwerk lernt **redundante Merkmale**1
    

---

#### ğŸ‘ **7. Analyse trainierter CNNs**

- **CAM (Class Activation Mapping)**: zeigt, wo das Netz "hinschaut"
- **Guided Backpropagation**: zeigt, welche Eingabepixel am wichtigsten waren

| Begriff                         | Bedeutung                                                          |
| ------------------------------- | ------------------------------------------------------------------ |
| **Logits**                      | Rohwerte vor der Softmax                                           |
| **Feature Maps**                | Zwischenergebnisse nach Faltungen (in CNNs)                        |
| **Pooling (z.â€¯B. Max Pooling)** | Verkleinert Feature Maps, wÃ¤hlt z.â€¯B. grÃ¶ÃŸtes Element aus Regionen |
| **Padding / Stride**            | Steuerung, wie Filter Ã¼ber Bild laufen                             |

