## **1.2 Lineare Regression**

### ğŸ¯ **Ziel:**

Ein Modell, das eine lineare Beziehung zwischen einer Eingabe XXX und einer Ausgabe yyy findet.

### ğŸ“ **Mathematisches Modell:**

$$y=wX+b$$

- X ist die Eingabematrix mit m Beispielen und n Features.
- w ist der Vektor der Gewichte.
- b ist der Bias-Wert.

### ğŸ”¢ **Fehlermetrik: Mean Squared Error (MSE)**

- MSE sagt aus fÃ¼r das Modell was **gut** oder **schlecht** ist.
$$
MSE=n1â€‹âˆ‘(y^â€‹iâ€‹âˆ’yiâ€‹)2
$$

### ğŸ”½ **Gradientenabstieg zur Optimierung**

- Berechnen Gradient des Fehlers damit wir wissen in welche Richtung wir uns bewegen mÃ¼ssen.
- Wir Ã¤ndern `w` und `b` ein kleines StÃ¼ck -> Modell wird besser

$$w := w - \alpha \frac{\partial J}{\partial w}$$
$$b := b - \alpha \frac{\partial J}{\partial b}$$

### ğŸ–¥ï¸ **Python-Implementierung**

```python
import numpy as np

  

# Daten generieren
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 6, 8, 10])

# Parameter initialisieren
w = 0.000
b = 0.000
alpha = 0.0025 Â # Lernrate
epochs = 1000

# Listen zum Speichern von Ã„nderungen
w_history = []
b_history = []

# Gradientenabstieg
for _ in range(epochs):
Â  Â  y_pred = w * X.flatten() + b Â # X muss flach sein
Â  Â  dw = (-2 / len(X)) * np.sum(X.flatten() * (y - y_pred)) Â # Skalar
Â  Â  db = (-2 / len(X)) * np.sum(y - y_pred) Â # Skalar
Â  Â  w -= alpha * dw
Â  Â  b -= alpha * db
Â  Â  w_history.append(w)
Â  Â  b_history.append(b)

print(f"Trainiertes Modell: y = {w}x + {b}")

import matplotlib.pyplot as plt

plt.scatter(X, y, label="Daten")
plt.plot(X, w*X + b, color='red', label="Regressionslinie")
plt.legend()
plt.show()
```

![[1_iB5TFe77kfkWIxzcLT92Wg.gif]]

### ğŸ” Das Ganze nochmal ganz bildlich:

Stell dir vor, dein Modell steht auf einem **Berg aus Fehlern**.

- Oben: Schlechter Fehler (groÃŸ)
- Unten: Kleiner Fehler (gut)

ğŸ‘‰ Der **MSE sagt dir**, wie hoch du gerade bist.  
ğŸ‘‰ Der **Gradient sagt dir**, in welche Richtung du runterlaufen musst.  
ğŸ‘‰ Der **Gradientenabstieg ist das Laufen**.


### ğŸ§  Wie die beiden zusammenspielen:

1. Du machst eine Vorhersage mit deinem aktuellen Modell.
2. Du berechnest den MSE â†’ **Wie schlecht ist das?**
3. Du berechnest den Gradienten des Fehlers â†’ **In welche Richtung mÃ¼ssen wir `w` und `b` Ã¤ndern?**
4. Du Ã¤nderst `w` und `b` ein kleines StÃ¼ck â†’ Modell wird besser.
5. Wiederhole das viele Male â†’ und du bekommst ein Modell, das sehr gute Vorhersagen macht!

### ğŸ” Beispielcode: Gradient und Lernrate


```Python
a_ = -0,5
a_history = -0.5
eta = 0.0003
for i in range(0,5):
Â  grad_a = -2/len(y)*np.sum((y -a_ * x - b) *x)
Â  a_ = a_ - eta*grad_a
Â  a_history =np.append(a_history,a_)
print(a_history)
```

Zeigt den Verlauf wie sich unser Modell verbessert.

`[-0.5 1.80415034 0.80054605 1.23767972 1.04728007 1.13021135]`

- a_ := Startwert
- eta := Ist die Lernrate(In wie groÃŸe AbstÃ¤nden gesprungen wird)
		- (Hohe Lernrate = Schneller, aber ungenauer)
		- (Kleine Lernrate = Langsamer, aber ziemlich genau)

**Probem: Finde eine gute Lernrate**
	- Idee: Adaptive Learning Rate(Passe die Lernrate an zB nach 5 DurchlÃ¤ufen oder andere Bedingungen)
zB:
#### ğŸš€ Dynamische Lernrate (Heuristik)

Idee:
- **Anfangs**: GroÃŸe Lernrate â†’ schnelleres Lernen
- **SpÃ¤ter**: Kleinere Lernrate â†’ feinere Anpassung

#### Beispiel: Alle 20 Elemente eta halbieren
```Python
eta = 0.1
for i in range(100):
    grad_a = ... # wie Ã¼blich
    a_ = a_ - eta * grad_a

    if i % 20 == 0:
        eta = eta * 0.5  # Lernrate halbieren

```
â¡ï¸ So verhinderst du Ãœberschwinger und machst das Modell prÃ¤ziser

#### Beispiel: Wenn sich der Gradient kaum noch Ã¤ndert â†’ Lernrate verringern
```Python
# Wenn sich der Gradient kaum noch Ã¤ndert â†’ Lernrate verringern
if abs(grad_a) < 0.01:
    eta = eta * 0.5
```
â¡ï¸ Das wÃ¤re eine einfache **Heuristik**:  
**â€Wenn kaum noch Verbesserung â†’ langsamer werdenâ€œ**



### 9. ğŸ² **Dropout**

#### WofÃ¼r braucht man das?
- Gegen **Overfitting**
- LÃ¤sst Netzwerk **robuster** und **generalisierender** lernen
    
#### ğŸ› ï¸ Wie setzt man es ein?

- WÃ¤hrend Training: zufÃ¤llig z.â€¯B. 50â€¯% der Neuronen deaktivieren
- WÃ¤hrend Test: **volle KapazitÃ¤t aktivieren**